# Docker Compose with SmolLM2 Model Runner (Correct Syntax)
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend
    environment:
      - REACT_APP_API_URL=http://localhost:8080

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - PORT=8080
    # Reference the LLM model - Docker will inject environment variables
    models:
      - llm

# Define models using the official Docker Compose models specification
models:
  llm:
    model: ai/smollm2:1.7B-Q8_0
    context_size: 4096
    runtime_flags:
      - "--threads=8"
      - "--ctx-size=4096"

networks:
  default:
    driver: bridge