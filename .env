# SmolLM2 Model Configuration for Mac GPU
LLM_MODEL_NAME=ai/smollm2:1.7B-Q8_0

# Backend API Configuration
BASE_URL=http://host.docker.internal:12434/engines/llama.cpp/v1/
MODEL=ai/smollm2:1.7B-Q8_0
API_KEY=dockermodelrunner